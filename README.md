# 🧠 AI vs Human Text Detector

This is a Streamlit web application that detects whether a given text was written by a human or generated by AI. It supports single prediction, batch processing, and model comparison using traditional ML models (SVM, Decision Tree, AdaBoost) and deep learning models (CNN, RNN, LSTM).

---

## 🚀 Features

- Single prediction via typed, pasted, or uploaded text (PDF, DOCX, TXT)
- Batch processing from CSV or TXT files
- Model comparison across all available classifiers
- Visual confidence charts and agreement analysis
- Trained models included (if under 100MB) or accessible via cloud

---

## 🧰 Tech Stack

- Python 3.9+
- Streamlit
- Scikit-learn
- PyTorch
- TensorFlow (for tokenization)
- Pandas, NumPy
- Matplotlib, Seaborn, Plotly
- PyPDF2, python-docx (for document parsing)

---

## 📂 Project Structure

```
project2_folder/
├── app_project2.py                 # Main Streamlit app
├── tokenizer.pickle               # Tokenizer used in preprocessing
├── CNN.pkl                        # CNN PyTorch model
├── LSTM.pkl                       # LSTM PyTorch model
├── RNN.pkl                        # RNN PyTorch model
├── svm_model.pkl                  # SVM model (scikit-learn)
├── adaboost_model.pkl             # Adaboost model (scikit-learn)
├── decision_tree_model.pkl        # Decision Tree model (scikit-learn)
├── embedding_matrix.npy           # Pretrained word embeddings
├── requirements.txt               # All dependencies
└── README.md                      # This file
```

---

## 🛠️ Setup Instructions

1. **Clone the repository:**
   ```bash
   git clone https://github.com/Lilian1341/Human-vs-Ai-detector.git
   cd Human-vs-Ai-detector
   ```

2. **Create and activate a virtual environment:**
   ```bash
   python -m venv venv
   venv\Scripts\activate    # Windows
   # OR
   source venv/bin/activate  # macOS/Linux
   ```

3. **Install dependencies:**
   ```bash
   pip install -r requirements.txt
   ```

4. **Run the Streamlit app:**
   ```bash
   streamlit run app_project2.py
   ```

---

## 🌐 Deployment Instructions (Streamlit Community Cloud)

1. Push your complete repo (with `app_project2.py`, model files, etc.) to GitHub.
2. Go to [Streamlit Cloud](https://streamlit.io/cloud).
3. Click “New App” and connect your GitHub repo.
4. Set the file path to `app_project2.py`.
5. Add any environment secrets if required.
6. Click **Deploy**.

---

## 🧪 How to Use the App

### 🔮 Single Prediction
- Paste or upload a document (TXT, PDF, DOCX).
- Select a model.
- Click **Predict** to see results.

### 📁 Batch Processing
- Upload a CSV (1st column = text) or TXT (one line per text).
- Choose a model and click **Process File**.

### ⚖️ Model Comparison
- Enter a single text.
- The app compares predictions from all available models.

---

## 📌 Notes for Developers

- **Tokenization:** Handled by Keras `Tokenizer` loaded from `tokenizer.pickle`.
- **Padding:** Inputs are padded to a max sequence length before being passed to the deep learning models.
- **DL Models:** Use `torch.nn.Module` subclasses (CNN, RNN, LSTM) with softmax output for binary classification.
- **Modular Prediction Logic:** Defined in `make_prediction()` and `predict_dl_model()`.

### ✅ Example Softmax Prediction Logic (for DL models)

```python
with torch.no_grad():
    output = model(input_tensor)
    probs = F.softmax(output, dim=1).cpu().numpy()[0]
    pred = int(probs.argmax())
```

---

## ✍️ Contributing

Pull requests are welcome. For major changes, please open an issue first to discuss the improvements.

---

## 📄 License

This project is open-source and available under the MIT License.

---

## 👩‍💻 Author

**Lilian Echebiri**  
Streamlit | Machine Learning | Natural Language Processing

[GitHub](https://github.com/Lilian1341)
